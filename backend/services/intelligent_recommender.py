"""
Intelligent Topic Recommendation Engine
Combines channel analysis with social media trends for personalized recommendations
"""

from typing import List, Dict, Optional
import numpy as np
from datetime import datetime


class TopicRecommendationEngine:
    """
    Advanced recommendation engine that matches trending topics with channel characteristics
    """
    
    def __init__(self):
        self.min_match_score = 30  # Minimum score to recommend
    
    def generate_recommendations(
        self,
        channel_analysis: Dict,
        social_trends: List[Dict],
        max_recommendations: int = 10
    ) -> List[Dict]:
        """
        Generate personalized topic recommendations
        
        Args:
            channel_analysis: Deep analysis of the channel
            social_trends: Trending topics from social media
            max_recommendations: Maximum number of recommendations
        
        Returns:
            List of recommended topics with detailed reasoning
        """
        recommendations = []
        
        # Extract channel characteristics
        channel_topics = [t['topic'] for t in channel_analysis.get('topics', [])]
        content_style = channel_analysis.get('content_style', {})
        target_audience = channel_analysis.get('target_audience', {})
        high_performers = channel_analysis.get('high_performers', {})
        
        for trend in social_trends:
            # Calculate match score
            match_result = self._calculate_match_score(
                trend,
                channel_topics,
                content_style,
                target_audience,
                high_performers
            )
            
            if match_result['match_score'] >= self.min_match_score:
                recommendations.append({
                    'keyword': trend['keyword'],
                    'match_score': match_result['match_score'],
                    'viral_potential': match_result['viral_potential'],
                    'performance_score': match_result['performance_score'],
                    'relevance_score': match_result['relevance_score'],
                    'opportunity_score': match_result['opportunity_score'],
                    'composite_social_score': trend.get('composite_score', 0),
                    'reasoning': match_result['reasoning'],
                    'content_angle': match_result['content_angle'],
                    'predicted_performance': match_result['predicted_performance'],
                    'suggested_format': match_result['suggested_format'],
                    'urgency': match_result['urgency'],
                    'sources': trend.get('sources', []),
                    'related_info': {
                        'rising_queries': trend.get('rising_queries', []),
                        'hashtags': trend.get('twitter_hashtags', []),
                        'subreddits': trend.get('reddit_subreddits', [])
                    }
                })
        
        # Deduplicate by keyword first (keep the one with highest match_score)
        seen_keywords = {}
        deduplicated = []
        for rec in recommendations:
            keyword_lower = rec['keyword'].lower().strip()
            if keyword_lower not in seen_keywords:
                seen_keywords[keyword_lower] = rec
                deduplicated.append(rec)
            else:
                # If duplicate, keep the one with higher match_score
                existing_rec = seen_keywords[keyword_lower]
                if rec['match_score'] > existing_rec['match_score']:
                    # Replace in both dict and list
                    seen_keywords[keyword_lower] = rec
                    existing_idx = deduplicated.index(existing_rec)
                    deduplicated[existing_idx] = rec
        
        # Sort by match score after deduplication
        deduplicated.sort(key=lambda x: x['match_score'], reverse=True)
        
        return deduplicated[:max_recommendations]
    
    def _calculate_match_score(
        self,
        trend: Dict,
        channel_topics: List[str],
        content_style: Dict,
        target_audience: Dict,
        high_performers: Dict
    ) -> Dict:
        """
        Calculate comprehensive match score between trend and channel
        
        New algorithm (as per user feedback):
        - äº’è”ç½‘çƒ­åº¦ (Viral Potential): 40%
        - è¡¨ç°æ½œåŠ› (Performance Score): 25%
        - å†…å®¹ç›¸å…³æ€§ (Relevance Score): 35%
        
        Returns a dict with match_score and detailed reasoning
        """
        keyword = trend['keyword'].lower()
        
        # 1. äº’è”ç½‘çƒ­åº¦ (Viral Potential) - 40%
        viral_potential = self._calculate_viral_potential(trend)
        
        # 2. è¡¨ç°æ½œåŠ› (Performance Score) - 25%
        performance_score = self._calculate_performance_potential(
            trend, 
            high_performers,
            channel_topics,
            content_style,
            target_audience
        )
        
        # 3. å†…å®¹ç›¸å…³æ€§ (Relevance Score) - 35%
        # Combine topic relevance, style compatibility, and audience fit
        topic_relevance = self._calculate_topic_relevance(keyword, channel_topics)
        style_score = self._calculate_style_compatibility(keyword, content_style)
        audience_score = self._calculate_audience_fit(keyword, target_audience)
        relevance_score = (topic_relevance * 0.5 + style_score * 0.3 + audience_score * 0.2)
        
        # 4. Opportunity Score (for display purposes)
        opportunity_score = self._calculate_opportunity_score(trend)
        
        # Composite match score with new weights
        match_score = (
            viral_potential * 0.4 +      # äº’è”ç½‘çƒ­åº¦ 40%
            performance_score * 0.25 +    # è¡¨ç°æ½œåŠ› 25%
            relevance_score * 0.35        # å†…å®¹ç›¸å…³æ€§ 35%
        )
        
        # Generate reasoning with new scores
        reasoning = self._generate_reasoning(
            keyword,
            viral_potential,
            performance_score,
            relevance_score,
            trend
        )
        
        # Generate content angle
        content_angle = self._generate_content_angle(
            keyword,
            content_style,
            trend
        )
        
        # Predict performance with new algorithm
        predicted_performance = self._predict_performance(
            match_score,
            viral_potential,
            performance_score,
            relevance_score,
            high_performers
        )
        
        # Suggest format
        suggested_format = self._suggest_format(keyword, content_style)
        
        # Determine urgency based on viral potential and growth
        urgency = self._determine_urgency(trend, viral_potential)
        
        return {
            'match_score': round(match_score, 2),
            'viral_potential': round(viral_potential, 2),
            'performance_score': round(performance_score, 2),
            'relevance_score': round(relevance_score, 2),
            'opportunity_score': round(opportunity_score, 2),
            'reasoning': reasoning,
            'content_angle': content_angle,
            'predicted_performance': predicted_performance,
            'suggested_format': suggested_format,
            'urgency': urgency
        }
    
    def _calculate_topic_relevance(self, keyword: str, channel_topics: List[str]) -> float:
        """
        Calculate how relevant the trending topic is to channel's existing topics
        """
        if not channel_topics:
            return 50  # Neutral score if no topics
        
        keyword_words = set(keyword.split())
        
        # Check for exact matches
        exact_matches = sum(1 for topic in channel_topics if topic in keyword)
        
        # Check for word overlaps
        word_overlaps = 0
        for topic in channel_topics:
            topic_words = set(topic.split())
            overlap = len(keyword_words & topic_words)
            word_overlaps += overlap
        
        # Calculate score
        relevance = (exact_matches * 20) + (word_overlaps * 10)
        
        return min(100, max(20, relevance))
    
    def _calculate_style_compatibility(self, keyword: str, content_style: Dict) -> float:
        """
        Check if trending topic fits the channel's content style
        """
        if not content_style:
            return 50
        
        primary_style = content_style.get('primary_style', '').lower()
        
        # Style-keyword compatibility matrix
        style_keywords = {
            'tutorial': ['how', 'guide', 'tips', 'learn', 'tutorial'],
            'review': ['review', 'unbox', 'test', 'compare', 'vs'],
            'entertainment': ['funny', 'challenge', 'prank', 'reaction'],
            'news': ['news', 'update', 'breaking', 'latest'],
            'educational': ['explain', 'science', 'facts', 'history'],
            'gaming': ['game', 'gaming', 'play', 'walkthrough'],
            'tech': ['tech', 'gadget', 'phone', 'software']
        }
        
        style_keywords_set = set(style_keywords.get(primary_style, []))
        keyword_lower = keyword.lower()
        
        # Check if keyword contains style-related terms
        matches = sum(1 for kw in style_keywords_set if kw in keyword_lower)
        
        compatibility = 50 + (matches * 15)
        
        return min(100, compatibility)
    
    def _calculate_audience_fit(self, keyword: str, target_audience: Dict) -> float:
        """
        Check if topic fits the target audience
        """
        if not target_audience:
            return 50
        
        age_group = target_audience.get('primary_age_group', 'general')
        
        # Age-appropriate topic indicators
        age_indicators = {
            'kids': ['kids', 'fun', 'cartoon', 'toy', 'game'],
            'teens': ['teen', 'tiktok', 'viral', 'meme', 'trend'],
            'young_adults': ['college', 'career', 'lifestyle', 'tech'],
            'adults': ['professional', 'finance', 'business', 'investment'],
            'all_ages': ['family', 'everyone', 'popular', 'trending']
        }
        
        indicators = age_indicators.get(age_group, age_indicators['all_ages'])
        keyword_lower = keyword.lower()
        
        matches = sum(1 for indicator in indicators if indicator in keyword_lower)
        
        fit_score = 50 + (matches * 12)
        
        return min(100, fit_score)
    
    def _calculate_viral_potential(self, trend: Dict) -> float:
        """
        è®¡ç®—äº’è”ç½‘çƒ­åº¦ (Viral Potential)
        è¡¡é‡è¯é¢˜åœ¨ç¤¾äº¤åª’ä½“çš„è®¨è®ºçƒ­åº¦
        
        è®¡ç®—ä¾æ®ï¼š
        - Twitter è®¨è®ºé‡å’Œè½¬å‘æ•°
        - Reddit å¸–å­æ•°å’Œç‚¹èµæ•°
        - Google Trends æœç´¢å¢é•¿ç‡
        - è·¨å¹³å°å‡ºç°æ¬¡æ•°
        """
        composite_score = trend.get('composite_score', 0)
        growth_rate = trend.get('growth_rate', 0)
        source_count = len(trend.get('sources', []))
        
        # åŸºç¡€çƒ­åº¦åˆ†æ•°
        base_score = composite_score
        
        # å¢é•¿åŠ æˆ
        growth_bonus = min(30, growth_rate * 0.3)  # æœ€å¤š30åˆ†åŠ æˆ
        
        # è·¨å¹³å°åŠ æˆ
        platform_bonus = min(20, (source_count - 1) * 10)  # å¤šå¹³å°é¢å¤–åŠ åˆ†
        
        viral_score = base_score + growth_bonus + platform_bonus
        
        return min(100, round(viral_score, 2))
    
    def _calculate_performance_potential(
        self,
        trend: Dict,
        high_performers: Dict,
        channel_topics: List[str],
        content_style: Dict,
        target_audience: Dict
    ) -> float:
        """
        è®¡ç®—è¡¨ç°æ½œåŠ› (Performance Score)
        é¢„æµ‹è¯¥è¯é¢˜è§†é¢‘çš„æ’­æ”¾è¡¨ç°
        
        åŸºäºï¼š
        - è¯é¢˜çƒ­åº¦è¶‹åŠ¿
        - é¢‘é“å†å²å¹³å‡æ’­æ”¾
        - ç›¸ä¼¼è¯é¢˜çš„è¡¨ç°
        - æ—¶æ•ˆæ€§åŠ æˆ
        """
        # åŸºç¡€çƒ­åº¦
        viral_potential = self._calculate_viral_potential(trend)
        
        # ç›¸å…³æ€§åŠ æˆï¼ˆç›¸å…³æ€§è¶Šé«˜ï¼Œè¡¨ç°æ½œåŠ›è¶Šå¤§ï¼‰
        keyword = trend['keyword'].lower()
        topic_relevance = self._calculate_topic_relevance(keyword, channel_topics)
        style_score = self._calculate_style_compatibility(keyword, content_style)
        audience_score = self._calculate_audience_fit(keyword, target_audience)
        relevance_bonus = (topic_relevance * 0.5 + style_score * 0.3 + audience_score * 0.2) * 0.3
        
        # æ—¶æ•ˆæ€§åŠ æˆï¼ˆå¿«é€Ÿå¢é•¿çš„è¯é¢˜æœ‰æ›´é«˜æ½œåŠ›ï¼‰
        growth_rate = trend.get('growth_rate', 0)
        timeliness_bonus = min(20, growth_rate * 0.2)
        
        # ç»¼åˆè¡¨ç°æ½œåŠ›
        performance_score = viral_potential * 0.6 + relevance_bonus + timeliness_bonus
        
        return min(100, round(performance_score, 2))
    
    def _calculate_opportunity_score(self, trend: Dict) -> float:
        """
        Calculate opportunity score based on social media engagement
        (Kept for backward compatibility)
        """
        return self._calculate_viral_potential(trend)
    
    def _generate_reasoning(
        self,
        keyword: str,
        viral_potential: float,
        performance_score: float,
        relevance_score: float,
        trend: Dict
    ) -> str:
        """
        Generate human-readable reasoning for the recommendation
        """
        reasons = []
        
        # äº’è”ç½‘çƒ­åº¦
        if viral_potential >= 90:
            reasons.append("ğŸ”¥ çˆ†ç«è¯é¢˜ï¼ˆå…¨ç½‘è®¨è®ºï¼‰")
        elif viral_potential >= 70:
            reasons.append("âš¡ çƒ­é—¨è¯é¢˜ï¼ˆå¿«é€Ÿä¸Šå‡ï¼‰")
        elif viral_potential >= 50:
            reasons.append("ğŸ“ˆ ä¸Šå‡è¯é¢˜ï¼ˆé€æ¸æµè¡Œï¼‰")
        else:
            reasons.append("ğŸ’¡ å°ä¼—è¯é¢˜")
        
        # å†…å®¹ç›¸å…³æ€§
        if relevance_score >= 90:
            reasons.append("å®Œç¾åŒ¹é…ï¼ˆæ ¸å¿ƒå†…å®¹ï¼‰")
        elif relevance_score >= 70:
            reasons.append("é«˜åº¦ç›¸å…³ï¼ˆæ‰©å±•å†…å®¹ï¼‰")
        elif relevance_score >= 50:
            reasons.append("ç›¸å…³ï¼ˆè·¨ç•Œå°è¯•ï¼‰")
        
        # è¡¨ç°æ½œåŠ›
        if performance_score >= 80:
            reasons.append("é¢„è®¡è¡¨ç°ä¼˜å¼‚")
        elif performance_score >= 60:
            reasons.append("é¢„è®¡è¡¨ç°è‰¯å¥½")
        
        # Sources
        sources = trend.get('sources', [])
        if len(sources) > 2:
            reasons.append(f"åœ¨{len(sources)}ä¸ªå¹³å°åŒæ—¶çƒ­é—¨")
        
        # Growth
        growth = trend.get('growth_rate', 0)
        if growth > 100:
            reasons.append(f"æœç´¢é‡å¢é•¿{growth:.0f}%ï¼Œè¶‹åŠ¿å¼ºåŠ²")
        
        return "ï¼›".join(reasons)
    
    def _generate_content_angle(
        self,
        keyword: str,
        content_style: Dict,
        trend: Dict
    ) -> str:
        """
        Suggest a specific content angle for the trending topic
        """
        primary_style = content_style.get('primary_style', 'general')
        growth_rate = trend.get('growth_rate', 0)
        
        angles = {
            'tutorial': f"åˆ¶ä½œ '{keyword}' å®Œæ•´æ•™ç¨‹ï¼Œåˆ†æ­¥è®²è§£",
            'review': f"æ·±åº¦è¯„æµ‹ '{keyword}'ï¼Œå¯¹æ¯”åˆ†æä¼˜åŠ£",
            'entertainment': f"æŒ‘æˆ˜/è¶£å‘³è§†é¢‘ï¼š'{keyword}' çˆ†ç¬‘åˆé›†",
            'news': f"'{keyword}' æœ€æ–°èµ„è®¯å’Œæ·±åº¦è§£è¯»",
            'educational': f"ç§‘æ™® '{keyword}'ï¼šåŸç†ã€å†å²å’Œåº”ç”¨",
            'gaming': f"'{keyword}' æ¸¸æˆå®å†µå’Œæ”»ç•¥æŒ‡å—",
            'tech': f"'{keyword}' æŠ€æœ¯åˆ†æå’Œä½¿ç”¨ä½“éªŒ"
        }
        
        base_angle = angles.get(primary_style, f"ä»ç‹¬ç‰¹è§’åº¦è§£è¯» '{keyword}'")
        
        # Add urgency if growing fast
        if growth_rate > 150:
            return f"ğŸ”¥ çƒ­ç‚¹ï¼{base_angle}ï¼ˆå»ºè®®48å°æ—¶å†…å‘å¸ƒï¼‰"
        elif growth_rate > 80:
            return f"âš¡ {base_angle}ï¼ˆå»ºè®®æœ¬å‘¨å†…å‘å¸ƒï¼‰"
        else:
            return f"ğŸ’¡ {base_angle}"
    
    def _predict_performance(
        self,
        match_score: float,
        viral_potential: float,
        performance_score: float,
        relevance_score: float,
        high_performers: Dict
    ) -> Dict:
        """
        é¢„æµ‹è§†é¢‘è¡¨ç° - ä¼˜åŒ–åçš„å¤šå› ç´ åŠ¨æ€è®¡ç®—
        
        æ”¹è¿›ç‚¹ï¼š
        1. ä½¿ç”¨ä¸­ä½æ•°è€Œéå¹³å‡å€¼ï¼ˆæ›´ç¨³å¥ï¼‰
        2. è€ƒè™‘é¢‘é“å¢é•¿è¶‹åŠ¿
        3. æ›´ç²¾ç»†çš„çƒ­åº¦ç³»æ•°è®¡ç®—
        4. æ·»åŠ æ ‡é¢˜ä¼˜åŒ–åŠ æˆ
        5. è€ƒè™‘é¢‘é“è§„æ¨¡è°ƒæ•´
        
        å…¬å¼ï¼š
        é¢„æµ‹æ’­æ”¾ = åŸºå‡†æ’­æ”¾ Ã— çƒ­åº¦ç³»æ•° Ã— ç›¸å…³æ€§ç³»æ•° Ã— è¡¨ç°æ½œåŠ›ç³»æ•° Ã— é¢‘é“è§„æ¨¡è°ƒæ•´ Ã— æ ‡é¢˜ä¼˜åŒ–åŠ æˆ
        """
        import random
        
        # 1. è·å–é¢‘é“å†å²æ’­æ”¾åŸºå‡†ï¼ˆä¼˜å…ˆä½¿ç”¨ä¸­ä½æ•°ï¼Œæ›´ç¨³å¥ï¼‰
        # ä¸­ä½æ•°å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿï¼Œæ›´é€‚åˆä½œä¸ºé¢„æµ‹åŸºå‡†
        median_views = high_performers.get('median_views') if high_performers else None
        avg_views = high_performers.get('avg_views') if high_performers else None
        
        # ä½¿ç”¨ä¸­ä½æ•°å’Œå¹³å‡å€¼çš„åŠ æƒå¹³å‡ï¼ˆä¸­ä½æ•°æƒé‡æ›´é«˜ï¼‰
        if median_views and avg_views:
            base_views = int(median_views * 0.7 + avg_views * 0.3)
        elif median_views:
            base_views = int(median_views)
        elif avg_views:
            base_views = int(avg_views)
        else:
            base_views = 10000  # é»˜è®¤å€¼
        
        # ç¡®ä¿æœ‰æœ‰æ•ˆçš„æ’­æ”¾é‡æ•°æ®
        if base_views <= 0:
            base_views = 10000
        
        # 2. é¢‘é“è§„æ¨¡è°ƒæ•´ï¼ˆå¤§é¢‘é“æ³¢åŠ¨æ›´å°ï¼Œå°é¢‘é“æ½œåŠ›æ›´å¤§ï¼‰
        total_videos = high_performers.get('total_videos', 0) if high_performers else 0
        if total_videos > 100:
            # æˆç†Ÿé¢‘é“ï¼Œæ³¢åŠ¨è¾ƒå°
            channel_stability = 0.95
        elif total_videos > 50:
            channel_stability = 1.0
        else:
            # æ–°é¢‘é“ï¼Œæ½œåŠ›æ›´å¤§ä½†æ³¢åŠ¨ä¹Ÿå¤§
            channel_stability = 1.1
        
        # 3. ä¼˜åŒ–åçš„çƒ­åº¦å¢é•¿ç³»æ•°ï¼ˆæ›´å¹³æ»‘çš„æ›²çº¿ï¼‰
        # ä½¿ç”¨è¿ç»­å‡½æ•°è€Œéåˆ†æ®µå‡½æ•°ï¼Œå‡å°‘çªå˜
        if viral_potential >= 90:
            viral_multiplier = 2.2 + (viral_potential - 90) * 0.03  # 2.2-2.5
        elif viral_potential >= 70:
            viral_multiplier = 1.6 + (viral_potential - 70) * 0.03  # 1.6-2.2
        elif viral_potential >= 50:
            viral_multiplier = 1.2 + (viral_potential - 50) * 0.02  # 1.2-1.6
        else:
            viral_multiplier = 0.9 + (viral_potential / 50) * 0.3  # 0.9-1.2
        
        # é™åˆ¶èŒƒå›´ï¼Œé¿å…æç«¯å€¼
        viral_multiplier = max(0.7, min(3.0, viral_multiplier))
        
        # 4. ç›¸å…³æ€§è°ƒæ•´ï¼ˆä½¿ç”¨æ›´ä¿å®ˆçš„èŒƒå›´ï¼‰
        # ç›¸å…³æ€§ä½æ—¶æƒ©ç½šæ›´å¤§ï¼Œç›¸å…³æ€§é«˜æ—¶å¥–åŠ±æ›´åˆç†
        if relevance_score >= 80:
            relevance_multiplier = 1.0 + (relevance_score - 80) * 0.01  # 1.0-1.2
        elif relevance_score >= 60:
            relevance_multiplier = 0.85 + (relevance_score - 60) * 0.0075  # 0.85-1.0
        elif relevance_score >= 40:
            relevance_multiplier = 0.75 + (relevance_score - 40) * 0.005  # 0.75-0.85
        else:
            relevance_multiplier = 0.65 + (relevance_score / 40) * 0.1  # 0.65-0.75
        
        # 5. è¡¨ç°æ½œåŠ›ç³»æ•°ï¼ˆæ›´ç²¾ç»†çš„è®¡ç®—ï¼‰
        if performance_score >= 80:
            performance_multiplier = 1.2 + (performance_score - 80) * 0.015  # 1.2-1.5
        elif performance_score >= 60:
            performance_multiplier = 1.0 + (performance_score - 60) * 0.01  # 1.0-1.2
        elif performance_score >= 40:
            performance_multiplier = 0.85 + (performance_score - 40) * 0.0075  # 0.85-1.0
        else:
            performance_multiplier = 0.7 + (performance_score / 40) * 0.15  # 0.7-0.85
        
        # 6. åŒ¹é…åº¦åŠ æˆï¼ˆæ—¶æ•ˆæ€§ï¼‰
        timeliness_multiplier = 0.9 + (match_score / 100) * 0.25  # 0.9-1.15
        
        # 7. æ ‡é¢˜ä¼˜åŒ–åŠ æˆï¼ˆå‡è®¾æ ‡é¢˜å·²ä¼˜åŒ–ï¼‰
        # åŸºäºé¢‘é“å†å²æœ€ä½³æ ‡é¢˜é•¿åº¦
        avg_title_length = high_performers.get('avg_title_length', 50) if high_performers else 50
        if 30 <= avg_title_length <= 60:
            title_optimization = 1.05  # æ ‡é¢˜é•¿åº¦é€‚ä¸­ï¼Œæœ‰5%åŠ æˆ
        else:
            title_optimization = 0.98  # æ ‡é¢˜é•¿åº¦ä¸ç†æƒ³ï¼Œè½»å¾®æƒ©ç½š
        
        # 8. ç»¼åˆè®¡ç®—ï¼ˆç§»é™¤éšæœºæ³¢åŠ¨ï¼Œä½¿ç”¨ç¡®å®šæ€§è®¡ç®—ï¼‰
        # éšæœºæ³¢åŠ¨ä¼šå¯¼è‡´é¢„æµ‹ä¸ç¨³å®šï¼Œæ”¹ç”¨åŸºäºmatch_scoreçš„ç¡®å®šæ€§è°ƒæ•´
        confidence_factor = 0.9 + (match_score / 100) * 0.2  # 0.9-1.1
        
        predicted_views = int(
            base_views * 
            viral_multiplier * 
            relevance_multiplier * 
            performance_multiplier * 
            timeliness_multiplier * 
            channel_stability *
            title_optimization *
            confidence_factor
        )
        
        # ç¡®ä¿æœ€å°å€¼ï¼Œä½†ä¸è¦è®¾ç½®è¿‡é«˜
        predicted_views = max(500, predicted_views)
        
        # 9. æ€§èƒ½ç­‰çº§ï¼ˆåŸºäºç»¼åˆåˆ†æ•°ï¼‰
        composite_score = (match_score * 0.4 + viral_potential * 0.3 + performance_score * 0.3)
        if composite_score >= 80:
            tier = 'excellent'
            description = "é¢„è®¡è¡¨ç°ä¼˜å¼‚ï¼Œå¯èƒ½æˆä¸ºçˆ†æ¬¾"
        elif composite_score >= 65:
            tier = 'good'
            description = "é¢„è®¡è¡¨ç°è‰¯å¥½ï¼Œé«˜äºå¹³å‡æ°´å¹³"
        elif composite_score >= 50:
            tier = 'moderate'
            description = "é¢„è®¡è¡¨ç°ä¸­ç­‰ï¼Œç¨³å®šæµé‡"
        else:
            tier = 'low'
            description = "é¢„è®¡è¡¨ç°ä¸€èˆ¬ï¼Œå¯ä½œä¸ºå°è¯•"
        
        return {
            'tier': tier,
            'predicted_views': predicted_views,
            'description': description,
            'confidence': round(composite_score, 0)
        }
    
    def _suggest_format(self, keyword: str, content_style: Dict) -> str:
        """
        Suggest video format based on keyword and channel style
        """
        primary_style = content_style.get('primary_style', 'general')
        
        formats = {
            'tutorial': '8-12åˆ†é’Ÿæ•™ç¨‹ï¼Œåˆ†æ­¥æ¼”ç¤º',
            'review': '10-15åˆ†é’Ÿæ·±åº¦è¯„æµ‹',
            'entertainment': '5-8åˆ†é’Ÿå¿«èŠ‚å¥å¨±ä¹',
            'news': '6-10åˆ†é’Ÿèµ„è®¯è§£è¯»',
            'educational': '10-15åˆ†é’ŸçŸ¥è¯†ç§‘æ™®',
            'gaming': '15-20åˆ†é’Ÿæ¸¸æˆå®å†µ',
            'tech': '8-12åˆ†é’Ÿäº§å“ä½“éªŒ'
        }
        
        return formats.get(primary_style, '8-12åˆ†é’Ÿç»¼åˆå†…å®¹')
    
    def _determine_urgency(self, trend: Dict, viral_potential: float) -> str:
        """
        ç¡®å®šç´§æ€¥åº¦ - åŸºäºæ–°çš„æƒé‡å’Œçƒ­åº¦åˆ†æ•°
        """
        growth_rate = trend.get('growth_rate', 0)
        
        # åŸºäºäº’è”ç½‘çƒ­åº¦å’Œå¢é•¿ç‡åˆ¤æ–­
        if viral_potential >= 90 or growth_rate > 200:
            return 'urgent'  # 48å°æ—¶å†…
        elif viral_potential >= 70 or growth_rate > 100:
            return 'high'    # æœ¬å‘¨å†…
        elif viral_potential >= 50 or growth_rate > 50:
            return 'medium'  # ä¸¤å‘¨å†…
        else:
            return 'low'     # çµæ´»å®‰æ’


class TitleGenerationEngine:
    """
    Generate optimized titles for recommended topics
    """
    
    def __init__(self):
        pass
    
    def generate_titles(
        self,
        recommendation: Dict,
        channel_analysis: Dict,
        count: int = 3
    ) -> List[Dict]:
        """
        Generate multiple title variants for a recommendation
        
        Args:
            recommendation: Topic recommendation with metadata
            channel_analysis: Channel characteristics
            count: Number of title variants to generate
        
        Returns:
            List of title variants with CTR predictions
        """
        keyword = recommendation['keyword']
        content_angle = recommendation['content_angle']
        high_performers = channel_analysis.get('high_performers', {})
        
        # Extract successful patterns from high-performing videos
        common_topics = high_performers.get('common_topics', [])
        avg_title_length = high_performers.get('avg_title_length', 60)
        
        # Generate different title strategies
        titles = []
        
        # Strategy 1: Number/List format (high CTR)
        titles.append({
            'title': self._generate_number_title(keyword),
            'strategy': 'number_list',
            'predicted_ctr': 8.5,
            'reasoning': 'æ•°å­—åˆ—è¡¨å¼æ ‡é¢˜ï¼Œé€šå¸¸æœ‰è¾ƒé«˜ç‚¹å‡»ç‡'
        })
        
        # Strategy 2: Question format (engagement)
        titles.append({
            'title': self._generate_question_title(keyword),
            'strategy': 'question',
            'predicted_ctr': 7.2,
            'reasoning': 'é—®é¢˜å¼æ ‡é¢˜ï¼Œæ¿€å‘å¥½å¥‡å¿ƒ'
        })
        
        # Strategy 3: Emotional hook (viral potential)
        titles.append({
            'title': self._generate_emotional_title(keyword, recommendation),
            'strategy': 'emotional',
            'predicted_ctr': 9.1,
            'reasoning': 'æƒ…æ„ŸåŒ–æ ‡é¢˜ï¼Œæ˜“å¼•å‘å…±é¸£å’Œåˆ†äº«'
        })
        
        # Optionally generate more variants
        if count > 3:
            titles.append({
                'title': self._generate_authority_title(keyword),
                'strategy': 'authority',
                'predicted_ctr': 7.8,
                'reasoning': 'æƒå¨å¼æ ‡é¢˜ï¼Œé€‚åˆä¸“ä¸šå†…å®¹'
            })
        
        # Adjust title length based on channel's successful pattern
        for title_data in titles:
            title_data['title'] = self._adjust_title_length(
                title_data['title'],
                avg_title_length
            )
            title_data['character_count'] = len(title_data['title'])
        
        return titles[:count]
    
    def _generate_number_title(self, keyword: str) -> str:
        """Generate title with numbers (e.g., "5 Ways to...")"""
        numbers = [3, 5, 7, 10]
        import random
        num = random.choice(numbers)
        
        templates = [
            f"{num}ä¸ªå…³äº{keyword}çš„å¿…çŸ¥æŠ€å·§",
            f"{keyword}å®Œæ•´æŒ‡å—ï¼š{num}ä¸ªå…³é”®ç‚¹",
            f"{num}ç§æ–¹æ³•ç©è½¬{keyword}",
            f"Top {num}ï¼š{keyword}æœ€ä½³å®è·µ"
        ]
        
        return random.choice(templates)
    
    def _generate_question_title(self, keyword: str) -> str:
        """Generate question-format title"""
        templates = [
            f"{keyword}çœŸçš„å€¼å¾—å—ï¼Ÿå®Œæ•´åˆ†æ",
            f"å¦‚ä½•é€‰æ‹©æœ€é€‚åˆçš„{keyword}ï¼Ÿ",
            f"{keyword}ä¸ºä»€ä¹ˆè¿™ä¹ˆç«ï¼Ÿæ·±åº¦è§£è¯»",
            f"ä½ çœŸçš„äº†è§£{keyword}å—ï¼Ÿ"
        ]
        
        import random
        return random.choice(templates)
    
    def _generate_emotional_title(self, keyword: str, recommendation: Dict) -> str:
        """Generate title with emotional hooks"""
        urgency = recommendation.get('urgency', 'low')
        
        if urgency == 'urgent':
            prefix = "ğŸ”¥ çˆ†ç«ï¼"
        elif urgency == 'high':
            prefix = "âš¡ è¶…ç«ï¼"
        else:
            prefix = ""
        
        templates = [
            f"{prefix}{keyword}ï¼š99%çš„äººéƒ½ä¸çŸ¥é“çš„ç§˜å¯†",
            f"{prefix}éœ‡æƒŠï¼{keyword}ç«Ÿç„¶è¿™æ ·ç”¨",
            f"{prefix}{keyword}å®Œå…¨æŒ‡å—ï¼šä»å…¥é—¨åˆ°ç²¾é€š",
            f"{prefix}åˆ«å†é”™è¿‡ï¼{keyword}å…¨é¢è§£æ"
        ]
        
        import random
        return random.choice(templates)
    
    def _generate_authority_title(self, keyword: str) -> str:
        """Generate authoritative/professional title"""
        templates = [
            f"{keyword}æ·±åº¦è¯„æµ‹ï¼šä¸“ä¸šè§†è§’",
            f"{keyword}å®Œæ•´åˆ†ææŠ¥å‘Š",
            f"ä¸“ä¸šè§£è¯»ï¼š{keyword}ç»ˆææŒ‡å—",
            f"{keyword}æƒå¨æµ‹è¯„ä¸æ¨è"
        ]
        
        import random
        return random.choice(templates)
    
    def _adjust_title_length(self, title: str, target_length: int) -> str:
        """
        Adjust title to optimal length based on channel's successful pattern
        """
        current_length = len(title)
        
        # If title is too long, trim it
        if current_length > target_length + 10:
            # Try to cut at a natural break point
            title = title[:int(target_length)] + '...'
        
        # YouTube optimal length is 50-70 characters
        if len(title) > 70:
            title = title[:67] + '...'
        
        return title


# Initialize engines
recommendation_engine = TopicRecommendationEngine()
title_engine = TitleGenerationEngine()
